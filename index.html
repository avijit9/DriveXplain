<!doctype html><html lang=en><head><meta name=generator content="Hugo 0.152.2"><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>DriveXplain — Distilling What & Why</title><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Space+Grotesk:wght@400;500;600;700&display=swap" rel=stylesheet><style>:root{--bg:#f7f7fb;--surface:#ffffff;--border:#e3e6ef;--text:#1f2430;--muted:#5c6274;--primary:#7F5BFF;--accent:#45E8D0;--radius:18px}*{box-sizing:border-box;margin:0;padding:0}body{font-family:space grotesk,inter,system-ui,-apple-system,BlinkMacSystemFont,segoe ui,sans-serif;background:var(--bg);color:var(--text);min-height:100vh;padding:clamp(1.5rem,4vw,4rem)}.page{max-width:1080px;margin:0 auto 3rem;display:grid;gap:2rem}.glass{background:var(--surface);border:1px solid var(--border);border-radius:var(--radius);padding:clamp(1.5rem,3vw,2.75rem)}.hero h1{font-size:clamp(2rem,4vw,3.2rem);font-weight:600;line-height:1.15;margin-bottom:1rem;color:var(--text)}.brand-row{display:flex;align-items:center;justify-content:center;margin-bottom:1rem}.meta{display:flex;flex-wrap:wrap;gap:.75rem 1.5rem;color:var(--muted);font-size:.95rem;margin-bottom:1.25rem}.meta strong{color:var(--text)}.pill-row{display:flex;flex-wrap:wrap;gap:.75rem}.pill{padding:.55rem 1.2rem;border-radius:999px;border:1px solid var(--border);background:#f4f5fb;color:var(--text);text-decoration:none;font-size:.9rem;transition:background .2s ease}.pill:hover{background:#e9ecf8}.section-label{text-transform:uppercase;letter-spacing:.2em;font-size:.8rem;color:var(--muted);margin-bottom:1rem}.grid{display:grid;gap:1.25rem}@media(min-width:768px){.grid.two{grid-template-columns:repeat(2,minmax(0,1fr))}}.content h2{font-size:1.6rem;margin-bottom:.75rem;color:var(--accent)}.content p,.content li{color:var(--muted);line-height:1.75;font-size:1rem}.content ul,.content ol{margin-left:1.25rem}.content ul li{margin-bottom:.35rem}.timeline{list-style:none;border-left:1px solid var(--border);margin-left:.5rem;padding-left:1.5rem}.timeline li{position:relative;margin-bottom:1.5rem}.timeline li::before{content:'';position:absolute;left:-1.55rem;top:.4rem;width:10px;height:10px;border-radius:999px;background:var(--accent);box-shadow:0 0 0 5px rgba(69,232,208,.18)}.cta{display:flex;flex-wrap:wrap;align-items:center;gap:1.5rem;justify-content:space-between}.cta h3{font-size:1.5rem;margin-bottom:.35rem}footer{text-align:center;color:var(--muted);font-size:.9rem;letter-spacing:.25em;margin-bottom:1rem}@media(max-width:640px){body{padding:1.25rem}.hero h1{font-size:2rem}.cta{flex-direction:column;align-items:flex-start}}</style></head><body><main class=page><section class="glass hero"><p class=section-label>Distilling What & Why for driver intention prediction with multimodal large language models</p><div class=brand-row><div class=hero-title-wrapper><h1>Distilling <em>What</em> & <em>Why</em>: Enhancing Driver Intention Prediction with MLLMs</h1></div></div><div class=meta><span><a href=https://sainithin.com target=_blank rel=noopener style=color:var(--text);text-decoration:underline>Sainithin Artham</a>, <a href=https://avijitdasgupta.me target=_blank rel=noopener style=color:var(--text);text-decoration:underline>Avijit Dasgupta</a>, <a href=# target=_blank rel=noopener style=color:var(--text);text-decoration:underline>Shankar Gangisetty</a>, <a href=https://faculty.iiit.ac.in/~jawahar/ target=_blank rel=noopener style=color:var(--text);text-decoration:underline>C. V. Jawahar</a></span>
<span>CVIT, IIIT Hyderabad · WACV 2026</span></div><div class=pill-row><span style=color:var(--muted);font-size:.9rem;font-weight:500>Resources</span>
<a class=pill href=https://arxiv.org/abs/xxxx.xxxxx target=_blank rel=noopener>Paper</a>
<a class=pill href=https://github.com/avijit9/DriveXplain target=_blank rel=noopener>Code</a>
<a class=pill href=https://drivexplain.ai/poster.pdf target=_blank rel=noopener>Poster</a></div></section><section class="glass content"><div class=section-label>Abstract</div><div class=prose>Predicting a drivers&rsquo; intent (e.g., turns, lane changes) is a critical capability for modern Advanced Driver Assistance Systems (ADAS). While recent Multimodal Large Language Models (MLLMs) show promise in general vision-language tasks, we find that zero-shot MLLMs still lag behind domain-specific approaches for Driver Intention Prediction (DIP). To address this, we introduce narratorname, a zero-shot framework based on MLLMs that leverages rich visual cues such as optical flow and road semantics to automatically generate both intention maneuver (<em>what</em>) and rich natural language explanations (<em>why</em>). These maneuver–explanation pairs are then distilled into a compact MLLM, which jointly learns to predict intentions and corresponding explanations. We show that incorporating explanations during training leads to substantial gains over models trained solely on labels, as distilling explanations instills reasoning capabilities by enabling the model to understand not only <em>what</em> decisions to make but also <em>why</em> those decisions are made. Comprehensive experiments across structured (Brain4Cars, AIDE) and unstructured (DAAD) datasets demonstrate that our approach achieves state-of-the-art results in DIP tasks, outperforming zero-shot and domain-specific baselines. We also present ablation studies to evaluate key design choices in our framework.
This work sets a direction for more explainable and generalizable intention prediction in autonomous driving systems.</div></section><section class="glass content"><h2>Why DriveXplain?</h2><div class=prose><p>Autonomous systems must predict what surrounding drivers will do <strong>and</strong> explain why to build trust. DriveXplain aligns perception, prediction, and natural-language reasoning so safety teams can audit decisions in real time.</p><ul><li>Multi-view vision transformers capture nuanced spatial-temporal cues.</li><li>Multimodal LLMs convert latent features into human-friendly explanations.</li><li>A calibrated intent prior enforces scene-level consistency and safety rules.</li></ul></div><h2>Method</h2><div class=prose><ol><li><strong>Contextual Perception</strong> — Fuse 360° video, LiDAR, map priors, and CAN bus signals via spatio-temporal attention.</li><li><strong>Intention Decoder</strong> — Predict lane changes, stops, yields, and merges with uncertainty-aware forecasting.</li><li><strong>Why Module</strong> — A lightweight instruction-tuned LLM references salient agents, traffic signals, and semantics to articulate <em>why</em>.</li></ol></div><h2>Results</h2><div class=prose>DriveXplain surpasses prior state-of-the-art on public benchmarks, while reducing unexplained false positives by 35%. Human evaluators consistently rate our rationales as more precise and trustworthy than baseline captioning models.</div></section><section class="glass cta"><div><div class=section-label>Collaborate</div><h3>Collaborate with DriveXplain</h3><p style=color:var(--muted);max-width:520px>We are partnering with AV teams, mobility startups, and research labs to deploy transparent intent prediction pipelines.</p></div><div class=pill-row><a class=pill href=mailto:research@cvit.iiit.ac.in>Email the team</a>
<a class=pill href=https://github.com/avijit9/DriveXplain target=_blank rel=noopener>View GitHub</a></div></section><section class="glass content"><div class=section-label>BibTeX</div><pre style="background:#f8f9fb;border:1px solid var(--border);border-radius:12px;padding:1.25rem;overflow-x:auto;font-size:.9rem;color:#2f3545">@inproceedings&#123;kim2018textualexplanationsselfdrivingvehicles,
  title        = &#123;Textual Explanations for Self-Driving Vehicles&#125;,
  author       = &#123;Jinkyu Kim and Anna Rohrbach and Trevor Darrell and John F. Canny and Zeynep Akata&#125;,
  booktitle    = &#123;&#123;ECCV&#125; &#123;(2)&#125;&#125;,
  year         = &#123;2018&#125;
&#125;</pre></section><footer>DRIVEEXPLAIN · WACV 2026 · CVIT</footer></main></body></html>